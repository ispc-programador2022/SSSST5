# Hi, we are the group SSSST5 üëã
[![flayer.png](https://i.postimg.cc/28bSv0fN/flayer.png)](https://postimg.cc/D8hh3dZx)

<hr>

## about us and the code

```js
const sssst5 = {
  pronouns: "he" | "she" | "they",
  code: [Python, HTML, CSS],
  tools: [PowerBi, SQL Server, Tableau],
}
```

##  COLABORADORES ‚úå
* __Sena Martin ismael__
* __Sierra Fernando__
* __Soria Julio Ezequiel__
* __Tissera Jorgelina__

> Esto es lo que una computadora significa para mi: es la herramienta m√°s notable que hemos logrado tener. Es como una bicicleta para nuestras mentes. - Steve Jobs

<hr>

<h4 align="left">1)¬øQu√© es un web Scraper?</h4>
<p align="text-justify">
Un scraper no es m√°s que un programa el cual tiene como finalidad extraer informaci√≥n de sitios web. Este tipo de programas regularmente simulan la navegaci√≥n de un usuario a trav√©s del protocolo HTTP. üòé<br>
Podemos ver a un scraper como un peque√±o bot, el cual, al nosotros indicar un target, es decir una p√°gina web, este comenzar√° un proceso de b√∫squeda y extracci√≥n de informaci√≥n. ü§ñ<br>
Al software dise√±ado para scrapear p√°ginas web com√∫nmente lo conoceremos como bot, spider, crawler o simplemente web scraper.<br>
La ventaja de un web scraper recae en su automatizaci√≥n. Si bien es cierto nosotros podemos extraer informaci√≥n de p√°ginas web, de forma manual, este proceso puede llevarnos una gran cantidad de tiempo y esfuerzo.<br>
Al nosotros realizar un web scraper debemos tomar muy en cuenta nuestro prop√≥sito. Recordemos que un scraper simula la navegaci√≥n de un usuario. Si en dado caso nuestro programa no contempla ciertos par√°metros, por ejemplo un n√∫mero limitado de peticiones o la rapidez con que estas se hacen, podemos hacer que el sitio web el cual estamos scrapeando tenga un rendimiento lento o inclusive llegue colapsar. Es por ello que hay que ser muy conscientes en el n√∫mero de peticiones y la forma en la cual obtendremos la p√°gina web .
</p>  

<h3 align="center">Tecnologias utilizadas</h3>

<h3 align="left">Languages and Tools:</h3>
<p align="left"> <a href="https://git-scm.com/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" alt="git" width="40" height="40"/> </a> <a href="https://www.mysql.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> <a href="https://www.selenium.dev" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/detain/svg-logos/780f25886640cef088af994181646db2f6b1a3f8/svg/selenium-logo.svg" alt="selenium" width="40" height="40"/> </a> </p>

<h4 align="center">
Detalles del codigo y sus funciones:
</h4>
<p>
Selenium tecnicamente hablando es un driver que nos permite a nosotros desde un lenguaje de programacion, poder automatizar las acciones que realiza el navegador, como si fuera un humano quien esta realizando las acciones, como por ejemplo "hacer click, sobre determinado boton", hacer un "scroll", "paginacion" y "extraer informaci√≤n" de la web indicada.
</p>

<h4 align="left">1) IMPORTAMOS LAS LIBRERIAS A UTILIZAR</h4>
<p align="left">
</p>

[![Captura1.jpg](https://i.postimg.cc/fbTpmjx1/Captura1.jpg)](https://postimg.cc/HrR6CMvt)

<h4 align="left">LIBRERIAS USADAS EN EL PROYECTO:</h4>
<p align="left">
</p>

*[Selenium](#Selenium)

*[Time](#Time)

*[Random](#Random)

*[Pandas](#Pandas)
<hr>

<h4 align="left">INSTANCIAR EL Chromedriver:</h4>
<p align="left">
</p>

<p>Dentro de una variable vamos a instanciar "chromedriver.exe", quien nos va a permitir hacer la simulaci√≥n en el navegador y abrir la web a traves del metodo "driver.get()"</p>

[![Captura2.jpg](https://i.postimg.cc/zBZrW2kp/Captura2.jpg)](https://postimg.cc/wtVZYVZs)

<hr>

<h4 align="left">INSPECCIONAR LA WEB:</h4>
<p align="left">
</p>

<p>De esta manera podremos visualizar los elementos de la web que corresponde al contenido de la web. En nuestro caso como se trata de extraer datos correspondientes a la descripci√≥n, modelo y precio, hacemos un recorrido para detectar cual o cuales son esos elementos que se repiten dentro del codigo html, para asi usarlos como referencias a la hora de seleccionarlo con el "xpath" y almacenada en una variable</p>

[![Captura3.jpg](https://i.postimg.cc/fTtkxp7Q/Captura3.jpg)](https://postimg.cc/jLTsT8kM)

<hr>

<h4 align="left">BOTON Y CICLO FOR:</h4>
<p align="left">
</p>

<p>Al hacer scroll sobre la web, nos topamos con que la misma no sigue cargando mas aritculos, sino que tiene un boton "CARGAR MAS" la cual permite traer mas resultados en la busqueda. Es por eso que se tuvo que detercar a traves de una inspeccion de la web y traer en codigo el xpath del mismo, para luego automatizar el click con la funcion ".click()".</p>
<p>La funcion "sleep" cumple una funci√≥n importante a la hora de la automatizaci√≥n, ya que el mismo permite darle un tiempo de espera a nuestro codigo y a la web, antes de seguir corriendo el script. Esta funcion debe ser lo mas parecida a un "humano", ya que si siempre damos un mismo valor, la web podria detectar que es un "robot" y asi es que evadimos si la misma tiene un detector de "bot", asi que es necesario "randomizar" ese intervalo de tiempo " sleep(random.uniform(8.0, 10.0))" Uniform lo que hace es darnos un valor aleatorio entre 8" y 10" </p>

[![Captura4.jpg](https://i.postimg.cc/436TZbz0/Captura4.jpg)](https://postimg.cc/sBgL4WHP)

<hr>
